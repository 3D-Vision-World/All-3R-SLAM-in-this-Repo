# 3D Geometric Foundation Models (3R) with SLAM

## Survey Paper

- Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.14501)] [[Website](https://fnzhan.com/projects/Feed-Forward-3D/)]

## 3D Geometric Foundation Models (3R)

- DUSt3R: Geometric 3D Vision Made Easy, *CVPR 2024*. [[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_DUSt3R_Geometric_3D_Vision_Made_Easy_CVPR_2024_paper.pdf)] [[Code](https://github.com/naver/dust3r)] [[Website](https://dust3r.europe.naverlabs.com/)]
- Monst3r: A simple approach for estimating geometry in the presence of motion, *ICLR 2025*. [[Paper](https://arxiv.org/pdf/2410.03825)] [[Code](https://github.com/Junyi42/monst3r)] [[Website](https://monst3r-project.github.io/)]
- LoRA3D: Low-Rank Self-Calibration of 3D Geometric Foundation Models, *ICLR 2025*. [[Paper](https://arxiv.org/pdf/2412.07746)] [[Website](https://520xyxyzq.github.io/lora3d/)]
- (CUT3R) Continuous 3D Perception Model with Persistent State, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2501.12387)] [[Code](https://github.com/CUT3R/CUT3R)] [[Website](https://cut3r.github.io/)]
- Reloc3r: Large-Scale Training of Relative Camera Pose Regression for Generalizable, Fast, and Accurate Visual Localization, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.08376)] [[Code](https://github.com/ffrivera0/reloc3r)]
- DAS3R: Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction, *arXiv 2024*. [[Paper](https://arxiv.org/pdf/2412.19584)] [[Code](https://github.com/kai422/das3r)] [[Website](https://kai422.github.io/DAS3R/)]
- MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion, *3DV 2025*. [[Paper](https://arxiv.org/pdf/2409.19152)] [[Code](https://github.com/naver/mast3r/tree/mast3r_sfm)]
- Splatt3R: Zero-shot Gaussian Splatting from Uncalibrated Image Pairs, *arXiv 2024*. [[Paper](https://arxiv.org/pdf/2408.13912)] [[Project](https://splatt3r.active.vision/)] [[Code](https://github.com/btsmart/splatt3r)]
- SAB3R: Semantic-Augmented Backbone in 3D Reconstruction, *arXiv 2024*. [[Paper](https://tianx-ia.github.io/Semantic_Augmented_3D_Foundation_Models.pdf)]
- No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images, *ICLR 2025*. [[Paper](https://arxiv.org/pdf/2410.24207)] [[Code](https://github.com/cvg/NoPoSplat)] [[Website](https://noposplat.github.io/)]
- Doppelgangers++: Improved Visual Disambiguation with Geometric 3D Features, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.05826)] [[Code](https://github.com/doppelgangers25/doppelgangers-plusplus)] [[Project](https://doppelgangers25.github.io/doppelgangers_plusplus/)]
- (Spann3R) 3D Reconstruction with Spatial Memory, *3DV 2025*. [[Paper](https://arxiv.org/pdf/2408.16061)] [[Code](https://github.com/HengyiWang/spann3r)] [[Website](https://hengyiwang.github.io/projects/spanner)]
- Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2501.13928)] [[Website](https://fast3r-3d.github.io/)] [[Code](https://github.com/facebookresearch/fast3r)]
- InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds, *arXiv 2025*. [[Paper](https://generative-vision.github.io/workshop-CVPR-24/papers/11.pdf)] [[Website](https://instantsplat.github.io/)] [[Code](https://github.com/NVlabs/InstantSplat)]
- SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction, *arXiv 2024*. [[Paper](https://arxiv.org/pdf/2411.12592)] [[Code](https://github.com/snldmt/SPARS3R)]
- Align3R: Aligned Monocular Depth Estimation for Dynamic Videos, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.03079)] [[Code](https://github.com/jiah-cloud/Align3R)] [[Website](https://igl-hkust.github.io/Align3R.github.io/)]
- (MASt3R) Grounding Image Matching in 3D with MASt3R, *ECCV 2024*. [[Paper](https://arxiv.org/pdf/2406.09756)] [[Code](https://github.com/naver/mast3r)] [[Website](https://europe.naverlabs.com/blog/mast3r-matching-and-stereo-3d-reconstruction/)]
- VGGT: Visual Geometry Grounded Transformer, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2503.11651)] [[Code](https://github.com/facebookresearch/vggt)] [[Website](https://vgg-t.github.io/)]
- E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2506.01933)] [[Code](https://github.com/VITA-Group/E3D-Bench)] [[Website](https://e3dbench.github.io/)]
- π^3: Scalable Permutation-Equivariant Visual Geometry Learning, *arXiv 2025*. [[Paper](https://arxiv.org/abs/2507.13347)] [[Code](https://github.com/yyfz/Pi3?tab=readme-ov-file)] [[Website](https://yyfz.github.io/pi3/)]
- Dens3R: A Foundation Model for 3D Geometry Prediction, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.16290v1)] [[Code](https://github.com/G-1nOnly/Dens3R)] [[Website](https://g-1nonly.github.io/Dens3R/)]
- LONG3R: Long Sequence Streaming 3D Reconstruction, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.18255)] [[Code](https://github.com/zgchen33/LONG3R/)] [[Website](https://zgchen33.github.io/LONG3R/)]
- PanoSplatt3R: Leveraging Perspective Pretraining for Generalized Unposed Wide-Baseline Panorama Reconstruction, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.21960)] [[Code]()] [[Website](https://npucvr.github.io/PanoSplatt3R/)]
- Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.22052)]
- G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2508.11379)]
- ViPE: Video Pose Engine for 3D Geometric Perception, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2508.10934)] [[Code](https://github.com/nv-tlabs/vipe)] [[Website](https://research.nvidia.com/labs/toronto-ai/vipe/)]
- FastVGGT: Training-Free Acceleration of Visual Geometry Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.02560)]
- SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2508.17972)] [[Code](https://github.com/HKUST-SAIL/sail-recon)] [[Website](https://hkust-sail.github.io/sail-recon/)]
- Streaming 4D Visual Geometry Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.11539)] [[Code](https://github.com/wzzheng/StreamVGGT)] [[Website](https://wzzheng.net/StreamVGGT/)]
- MapAnything: Universal Feed-Forward Metric 3D Reconstruction, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.13414)] [[Code](https://github.com/facebookresearch/map-anything)] [[Website](https://map-anything.github.io/)]
- TTT3R: 3D Reconstruction as Test-Time Training, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.26645)] [[Code](https://github.com/Inception3D/TTT3R)] [[Website](https://rover-xingyu.github.io/TTT3R/)]
- Co-Me: Confidence Guided Token Merging for Visual Geometric Transformers, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2511.14751)] [[Code](https://github.com/co-me-tokens/CoMe)] [[Website](https://co-me-tokens.github.io/)]
- MB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2511.20343)]
- VG3T: Visual Geometry Grounded Gaussian Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2512.05988)]
- KV-Tracker: Real-Time Pose Tracking with Transformers, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2512.22581)] [[Website](https://marwan99.github.io/kv_tracker/)]
- V-DPM: 4D Video Reconstruction with Dynamic Point Mapss, *arXiv 2026*. [[Paper](https://arxiv.org/pdf/2601.09499)] [[Website](https://www.robots.ox.ac.uk/~vgg/research/vdpm/)] [[Code](https://github.com/eldar/vdpm)]
- S-MUSt3R: Sliding Multi-view 3D Reconstruction, *arXiv 2026*. [[Paper](https://arxiv.org/pdf/2602.04517)] 


## SLAM

- Hier-slam++: Neuro-symbolic semantic slam with a hierarchically categorical gaussian splatting, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2502.14931)]
- MegaSaM: Accurate, Fast, and Robust Structure and Motion from Casual Dynamic Videos, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.04463)] [[Website](https://mega-sam.github.io/)] [[Code](https://github.com/mega-sam/mega-sam)]
- SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.09401)] [[Code](https://github.com/PKU-VCL-3DV/SLAM3R)]
- MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.12392)] [[Website](https://edexheim.github.io/mast3r-slam/)] [[Code](https://github.com/rmurai0610/MASt3R-SLAM)]
- VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2505.12549)] [[Code](https://github.com/MIT-SPARK/VGGT-SLAM)]
- Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.03737)] [[Website](https://3dagentworld.github.io/S3PO-GS/)] [[Code](https://github.com/3DAgentWorld/S3PO-GS)]
- VGGT-Long: Chunk it, Loop it, Align it – Pushing VGGT’s Limits on Kilometer-scale Long RGB Sequences, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.16443)] [[Code](https://github.com/DengKaiCQ/VGGT-Long)]
- Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline, *IROS, 2025*. [[Paper](https://arxiv.org/pdf/2508.04597)] [[Code](https://github.com/wangyr22/DepthGS)]
- 3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM, *RAL, 2025*. [[Paper](https://ieeexplore.ieee.org/document/11159173)]
- ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association, *3DV, 2026*. [[Paper](https://arxiv.org/pdf/2509.01584)] [[Code](https://github.com/zhangganlin/vista-slam)]
- SLAM-Former: Putting SLAM into One Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.16909)] [[Website](https://tsinghua-mars-lab.github.io/SLAM-Former/)] [[Code](https://github.com/Tsinghua-MARS-Lab/SLAM-Former)]
- MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2509.20757)] [[Code](https://github.com/GREAT-WHU/MASt3R-Fusion)]
- GRS-SLAM3R: Real-Time Dense SLAM with Gated Recurrent State, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2509.23737)]
- EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2510.02080v1)] [[Website](https://h0xg.github.io/ec3r/)] [[Code](https://github.com/h0xg/ec3r-slam)]
- Visual Odometry with Transformers, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2510.03348)] [[Website](https://vladimiryugay.github.io/vot/index.html)] [[Code](https://github.com/VladimirYugay/VoT)]
- ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2510.08551)] [[Website](https://city-super.github.io/artdeco/)] [[Code](https://github.com/InternRobotics/ARTDECO)]
- MASt3R-GS: Bridging 3D Reconstruction Priors with Gaussian Splatting for Real-Time Dense SLAM, *IROSw, 2025*. [[Paper](https://robogen-iros.github.io/accepted/12_MASt3R_GS_Bridging_3D_Recon.pdf)]
- LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2511.01186)]
- Building temporally coherent 3D maps with VGGT for memory-efficient Semantic SLAM, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2511.16282)]
- SING3R-SLAM: Submap-based Indoor Monocular Gaussian SLAM with 3D Reconstruction Prior, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2511.17207)]
- KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2512.01889)] [[Code](https://github.com/be2rlab/km-vipe)]
- Dynamic Visual SLAM using a General 3D Prior, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2512.06868)] [[Code](https://github.com/PRBonn/Pi3MOS-SLAM)]
- OpenMonoGS-SLAM: Monocular Gaussian Splatting SLAM with Open-set Semantics, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2512.08625)]
- Keyframe-Based Feed-Forward Visual Odometry, *arXiv 2026*. [[Paper](https://arxiv.org/pdf/2601.16020)] 
- VGGT-SLAM 2.0: Real time Dense Feed-forward Scene Reconstruction, *arXiv 2026*. [[Paper](https://arxiv.org/pdf/2601.19887)]
- VGGT-Motion: Motion-Aware Calibration-Free Monocular SLAM for Long-Range Consistency, *arXiv 2026*. [[Paper](https://arxiv.org/pdf/2602.05508)]
- VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation, *arXiv 2026*. [[Paper](https://arxiv.org/pdf/2602.15899)]
- VGGT-Geo: Probabilistic Geometric Fusion of Visual Geometry Grounded Transformer Priors for Robust Dense Indoor SLAM, *ISPRS International Journal of Geo-Information 2026*. [[Paper](https://www.mdpi.com/2220-9964/15/2/85)]

## Calibration
- Calib3R: A 3D Foundation Model for Multi-Camera to Robot Calibration and 3D Metric-Scaled Scene Reconstruction, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.08813)]

## Loop Closure Detection
- Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2511.05404)]


## Downstream Tasks
- SpatialLM: Training Large Language Models for Structured Indoor Modeling, *NIPS 2025*. [[Paper](https://arxiv.org/pdf/2506.07491)] [[Website](https://manycore-research.github.io/SpatialLM/)] [[Code](https://github.com/manycore-research/SpatialLM)]
- Reloc-VGGT: Visual Re-localization with Geometry Grounded Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2512.21883)] [[Code](https://github.com/dtc111111/Reloc-VGGT)]
- UniPR-3D: Towards Universal Visual Place Recognition with Visual Geometry Grounded Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2512.21078)] [[Code](https://github.com/dtc111111/UniPR-3D)]
