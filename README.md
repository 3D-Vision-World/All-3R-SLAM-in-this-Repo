# 3D Geometric Foundation Models (3R) with SLAM

## Survey Paper

- Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.14501)] [[Website](https://fnzhan.com/projects/Feed-Forward-3D/)]

## 3D Geometric Foundation Models (3R)

- DUSt3R: Geometric 3D Vision Made Easy, *CVPR 2024*. [[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_DUSt3R_Geometric_3D_Vision_Made_Easy_CVPR_2024_paper.pdf)] [[Code](https://github.com/naver/dust3r)] [[Website](https://dust3r.europe.naverlabs.com/)]
- Monst3r: A simple approach for estimating geometry in the presence of motion, *ICLR 2025*. [[Paper](https://arxiv.org/pdf/2410.03825)] [[Code](https://github.com/Junyi42/monst3r)] [[Website](https://monst3r-project.github.io/)]
- LoRA3D: Low-Rank Self-Calibration of 3D Geometric Foundation Models, *ICLR 2025*. [[Paper](https://arxiv.org/pdf/2412.07746)] [[Website](https://520xyxyzq.github.io/lora3d/)]
- (CUT3R) Continuous 3D Perception Model with Persistent State, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2501.12387)] [[Code](https://github.com/CUT3R/CUT3R)] [[Website](https://cut3r.github.io/)]
- Reloc3r: Large-Scale Training of Relative Camera Pose Regression for Generalizable, Fast, and Accurate Visual Localization, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.08376)] [[Code](https://github.com/ffrivera0/reloc3r)]
- DAS3R: Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction, *arXiv 2024*. [[Paper](https://arxiv.org/pdf/2412.19584)] [[Code](https://github.com/kai422/das3r)] [[Website](https://kai422.github.io/DAS3R/)]
- MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion, *3DV 2025*. [[Paper](https://arxiv.org/pdf/2409.19152)] [[Code](https://github.com/naver/mast3r/tree/mast3r_sfm)]
- Splatt3R: Zero-shot Gaussian Splatting from Uncalibrated Image Pairs, *arXiv 2024*. [[Paper](https://arxiv.org/pdf/2408.13912)] [[Project](https://splatt3r.active.vision/)] [[Code](https://github.com/btsmart/splatt3r)]
- SAB3R: Semantic-Augmented Backbone in 3D Reconstruction, *arXiv 2024*. [[Paper](https://tianx-ia.github.io/Semantic_Augmented_3D_Foundation_Models.pdf)]
- No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images, *ICLR 2025*. [[Paper](https://arxiv.org/pdf/2410.24207)] [[Code](https://github.com/cvg/NoPoSplat)] [[Website](https://noposplat.github.io/)]
- Doppelgangers++: Improved Visual Disambiguation with Geometric 3D Features, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.05826)] [[Code](https://github.com/doppelgangers25/doppelgangers-plusplus)] [[Project](https://doppelgangers25.github.io/doppelgangers_plusplus/)]
- (Spann3R) 3D Reconstruction with Spatial Memory, *3DV 2025*. [[Paper](https://arxiv.org/pdf/2408.16061)] [[Code](https://github.com/HengyiWang/spann3r)] [[Website](https://hengyiwang.github.io/projects/spanner)]
- Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2501.13928)] [[Website](https://fast3r-3d.github.io/)] [[Code](https://github.com/facebookresearch/fast3r)]
- InstantSplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds, *arXiv 2025*. [[Paper](https://generative-vision.github.io/workshop-CVPR-24/papers/11.pdf)] [[Website](https://instantsplat.github.io/)] [[Code](https://github.com/NVlabs/InstantSplat)]
- SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction, *arXiv 2024*. [[Paper](https://arxiv.org/pdf/2411.12592)] [[Code](https://github.com/snldmt/SPARS3R)]
- Align3R: Aligned Monocular Depth Estimation for Dynamic Videos, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.03079)] [[Code](https://github.com/jiah-cloud/Align3R)] [[Website](https://igl-hkust.github.io/Align3R.github.io/)]
- (MASt3R) Grounding Image Matching in 3D with MASt3R, *ECCV 2024*. [[Paper](https://arxiv.org/pdf/2406.09756)] [[Code](https://github.com/naver/mast3r)] [[Website](https://europe.naverlabs.com/blog/mast3r-matching-and-stereo-3d-reconstruction/)]
- VGGT: Visual Geometry Grounded Transformer, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2503.11651)] [[Code](https://github.com/facebookresearch/vggt)] [[Website](https://vgg-t.github.io/)]
- E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2506.01933)] [[Code](https://github.com/VITA-Group/E3D-Bench)] [[Website](https://e3dbench.github.io/)]
- π^3: Scalable Permutation-Equivariant Visual Geometry Learning, *arXiv 2025*. [[Paper](https://arxiv.org/abs/2507.13347)] [[Code](https://github.com/yyfz/Pi3?tab=readme-ov-file)] [[Website](https://yyfz.github.io/pi3/)]
- Dens3R: A Foundation Model for 3D Geometry Prediction, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.16290v1)] [[Code](https://github.com/G-1nOnly/Dens3R)] [[Website](https://g-1nonly.github.io/Dens3R/)]
- LONG3R: Long Sequence Streaming 3D Reconstruction, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.18255)] [[Code](https://github.com/zgchen33/LONG3R/)] [[Website](https://zgchen33.github.io/LONG3R/)]
- PanoSplatt3R: Leveraging Perspective Pretraining for Generalized Unposed Wide-Baseline Panorama Reconstruction, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.21960)] [[Code]()] [[Website](https://npucvr.github.io/PanoSplatt3R/)]
- Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.22052)]
- G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2508.11379)]
- ViPE: Video Pose Engine for 3D Geometric Perception, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2508.10934)] [[Code](https://github.com/nv-tlabs/vipe)] [[Website](https://research.nvidia.com/labs/toronto-ai/vipe/)]
- FastVGGT: Training-Free Acceleration of Visual Geometry Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.02560)]
- SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2508.17972)] [[Code](https://github.com/HKUST-SAIL/sail-recon)] [[Website](https://hkust-sail.github.io/sail-recon/)]
- Streaming 4D Visual Geometry Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.11539)] [[Code](https://github.com/wzzheng/StreamVGGT)] [[Website](https://wzzheng.net/StreamVGGT/)]
- MapAnything: Universal Feed-Forward Metric 3D Reconstruction, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.13414)] [[Code](https://github.com/facebookresearch/map-anything)] [[Website](https://map-anything.github.io/)]


## SLAM

- Hier-slam++: Neuro-symbolic semantic slam with a hierarchically categorical gaussian splatting, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2502.14931)]
- MegaSaM: Accurate, Fast, and Robust Structure and Motion from Casual Dynamic Videos, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.04463)] [[Website](https://mega-sam.github.io/)] [[Code](https://github.com/mega-sam/mega-sam)]
- SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.09401)] [[Code](https://github.com/PKU-VCL-3DV/SLAM3R)]
- MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors, *CVPR 2025*. [[Paper](https://arxiv.org/pdf/2412.12392)] [[Website](https://edexheim.github.io/mast3r-slam/)] [[Code](https://github.com/rmurai0610/MASt3R-SLAM)]
- VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2505.12549)] [[Code](https://github.com/MIT-SPARK/VGGT-SLAM)]
- Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps, *ICCV 2025*. [[Paper](https://arxiv.org/pdf/2507.03737)] [[Website](https://3dagentworld.github.io/S3PO-GS/)] [[Code](https://github.com/3DAgentWorld/S3PO-GS)]
- VGGT-Long: Chunk it, Loop it, Align it – Pushing VGGT’s Limits on Kilometer-scale Long RGB Sequences, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2507.16443)] [[Code](https://github.com/DengKaiCQ/VGGT-Long)]
- Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline, *IROS, 2025*. [[Paper](https://arxiv.org/pdf/2508.04597)] [[Code](https://github.com/wangyr22/DepthGS)]
- 3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM, *RAL, 2025*. [[Paper](https://ieeexplore.ieee.org/document/11159173)]
- ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association, *ICCV, 2025*. [[Paper](https://arxiv.org/pdf/2509.01584)] [[Code](https://github.com/zhangganlin/vista-slam)]
- SLAM-Former: Putting SLAM into One Transformer, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.16909)] [[Website](https://tsinghua-mars-lab.github.io/SLAM-Former/)] [[Code](https://github.com/Tsinghua-MARS-Lab/SLAM-Former)]
- MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2509.20757)] [[Code](https://github.com/GREAT-WHU/MASt3R-Fusion)]
- GRS-SLAM3R: Real-Time Dense SLAM with Gated Recurrent State, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2509.23737)]
- EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction, *arXiv, 2025*. [[Paper](https://arxiv.org/pdf/2510.02080v1)] [[Website](https://h0xg.github.io/ec3r/)] [[Code](https://github.com/h0xg/ec3r-slam)]

## Calibration
- Calib3R: A 3D Foundation Model for Multi-Camera to Robot Calibration and 3D Metric-Scaled Scene Reconstruction, *arXiv 2025*. [[Paper](https://arxiv.org/pdf/2509.08813)]
